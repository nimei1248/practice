使用mysql为什么还需要nosql这类产品？
1。数据库本身也有buffer，为什么还需要redis这类产品？
mysql:
  流程复杂，建立tcp连接，分配线程，权限验证，sql解析，获取数据等
  buffer pool以page为单位，尽管根据pk仅查询一条记录，也会读取整个页及相关页，buffer pool造成内存浪费

redis：
  简单，k/v结构，list，set
  更快速，无需认证
  基于结果的缓存可以为kv结构

redis并发能力：
做缓存加速，需要先做性能测试
redis-benchmark 压力测试
redis-benchmark -h ipaddress  --单机内的，没有通过网络的测试
多少个请求，多久完成，每个values多少字节，默认3个字节，很小
get获取values时间

pip install pymysql redis
做测试前，将redis的缓存清空，flushdb
通过redis python脚步测试 --
1。本机测试  7438
2。跨网络测试，相同网段，不同网段分别测试 2818
3。顺序单线程测试qps很低，注意测试是：单线程还是多线程
4。redis貌似只能使用一个cpu，建立tcp连接，3次握手，走网络tcp有很多连接损耗，网络质量好不好等
5。最好用万兆网络跑redis，对网络要求比较高
6。一般redis不会是瓶颈，网卡/带宽是瓶颈

通过mysql python脚步测试 --
mysql 跨网络875

redis qps受限于网卡，带宽
千兆网卡，最大可以跑到110MB/s
redis qps = 110 * 1024 * 1024(字节) / 8 / 字节数(业务数据传输的字节数)


常见nosql产品推荐：

redis生产环境部署注意事项：

redis常见数据结构：

redis运维注意事项：

总结：

redis 与 mysql如何结合：

从redis读数据流程：select
程序先到redis取，如果有，则直接返回给用户
没有则去db取，取完存放一份到redis，返回给用户(前后关系？)

往redis写数据流程：insert update delete
写数据的场景：insert update delete
把redis做成队列场景，不是很严谨，可能会丢数据，通过redis的list数据类型实现

insert写db后，再写redis，返回给用户：
   特殊地方：可能会挤走redis中活跃的数据，因此需要控制哪些只写db而不加载到redis(即，单存写数据到db)，需要的时候再加载到redis

先update、delete db中的数据，再更新redis，再很短暂的时间内，redis中的数据相比db是旧数据：
既然是用于缓存场景出现短暂不一致是很正常的，数据一致性要求没有那么严格，要求的是快
redis用于加速场景，而不能用于交易场景
解决方法：
将update、delete db and redis作为一个整体，作为一个大事务，通过java事务框架什么的(spring)，update、delete完db后，必须update、delete redis才算成功
或者先update、delete redis再db

上产环境部署注意事项：
https://redis.io
目前最新版本5。0：
wget http://download.redis.io/releases/redis-5.0.0.tar.gz
tar xzf redis-5.0.0.tar.gz
cd redis-5.0.0
makes / make MALLOC=jemalloc
make install

启动redis：
$ src/redis-server /data/redis/inst1/6379.conf

You can interact with Redis using the built-in client:
$ src/redis-cli
redis> set foo bar
OK
redis> get foo
"bar"

redis目录结构：
6379.conf

redis内存大小设置多大合适？
bgsave -- 将数据持久化 rdb 往磁盘写数据，将当前内存中的数据镜像一份到磁盘，如果操作系统内存不足，就会发生swap或oom
如何解决：
控制redis内存大小：
默认配置是内存一半左右，redis默认配置文件也可以运行，很可怕
redis需要多大内存，怎么利用内存？
随着数据量的增大，redis维护hash链也是需要内存开销的
特别是高速更新时update(存在内存拷贝/镜像的过程)，redis内存需要翻倍的，简单insert不需要翻倍
(avg(key) + avg(values)) * key_num(key的个数) * 2 = redis分配的内存

redis实例多怎么解决：
采用docker运行redis，同时可以做资源隔离

python 自动化
yaml   配置管理

saltstack：agent模型，ansible大规则场景可能有瓶颈

建议声明内存大小：
  最大不要超过10g
  建议：1g 2g 4g 5g这样的组合

考虑数据持久化和缓存的区别：
用了redis后没有效果或更慢，为啥？
取出redis中数据分析，多个业务共用一个redis实例：
   a业务没有设置key过期时间，b业务设置key有过期时间，导致b业务的数据总是在内存中被踢掉
   当内存不够使用时，redis会优先删除设置过期的数据，没设置的保留久一些
   总结：对于使用同一个redis，存在不同的业务，都要指定key过期时间/规则并且是一样的，否则一个很长，一个很短，还是会导致数据被踢出内存
   redis默认没有开启LRU： last recently used 最近最少使用原则，redis貌似没有严格准守lru算法，为了快
   redis默认没有开启LRU：假如是100m内存，现在使用内存接近100m，已经到100m会出现redis卡着不动情况，无法连接到redis，flush db都没有机会
     因此要做好内存监控，开启lru
    
要不要密码：
   redis密码设置比较简单，要么可以连接，要么不可以
   redis cluster设置密码貌似比较复杂

安全命令处理：
   基于单进程的，所有的操作都是一个一个来的
   这样会导致贝来不该慢的会变慢，在并发场景，如50个并发
   如keys * 运行2。07s，那么会阻塞其它的命令，直到keys命令运行完毕，因为redis没有锁的机制
   解决方法：慢命令改写
   rename-command keys/flushdb/config/ md5值

   如何正确获取keys及分析redis：
   redis>bgsave  -- 做分析时，最好在slave上做bgsave
   6379.rdb文件

   redis>info 
   used_memory_peak_human: 80.39M, 压缩完63M

通过下面工具分析rdb，存储什么key，什么values：
https://github.com/sripathikrishnan/redis-rdb-tools
Parse Redis dump.rdb files, Analyze Memory, and Export Data to JSON https://rdbtools.com

pip install rdbtools python-lzf
To install from source :

git clone https://github.com/sripathikrishnan/redis-rdb-tools
cd redis-rdb-tools
sudo python setup.py install

> rdb --command json /var/redis/6379/dump.rdb
[{
"user003":{"fname":"Ron","sname":"Bumquist"},
"lizards":["Bush anole","Jackson's chameleon","Komodo dragon","Ground agama","Bearded dragon"],
"user001":{"fname":"Raoul","sname":"Duke"},
"user002":{"fname":"Gonzo","sname":"Dr"},
"user_list":["user003","user002","user001"]},{
"baloon":{"helium":"birthdays","medical":"angioplasty","weather":"meteorology"},
"armadillo":["chacoan naked-tailed","giant","Andean hairy","nine-banded","pink fairy"],
"aroma":{"pungent":"vinegar","putrid":"rotten eggs","floral":"roses"}}]


redis命中率：
redis> info

# keyspace
db1:keys=100001,expires=0, avg_ttl=0
redis> select 0
redis> info
keyspace_hits:1
keyspace_misses:0  -- get key不存在，如果这个值增加很频繁说明什么？
同时踢出出去key也很多：
evicted_keys: 0
说明内存不够使用

total_commands_processed:13

获取设置的内存：
config get maxmemory
获取到最大值后，需要与used_memory_peak_human: 80.39M 或 used_memory_peak：84297152进行对比
如果接近80%-90%，那么就要报警，考虑扩容

如果计算命中和非命中率：
命中率=keyspace_hits / (keyspace_hits + keyspace_misses) * 100
非命中率=keyspace_misses / (keyspace_hits + keyspace_misses) * 100
其实知道其中一个就知道另一个了

与开发确认redis使用规范：
使用redis采用什么结构，如k/v结构、set、hash结构
用什么，存什么，常用命令是什么，提供一份大概说明

线上分析上有哪些请求命令：
类似于mysql show processlist; 计算命令使用分布
比如，redis慢，cpu过高，那么此时redis在做什么，用于分析
facebook: redis-faina 2012已经不在维护了，找找其它工具
底层调用的是redis monitor命令，将使用命令做分析、统计，看看哪些最耗时

redis监控：

常见类型：
k/v、list、set、hash、订阅(消息队列中概念 rocketmq、kafka)
redis集群、sentinel等都是通过订阅确定谁是谁

运维注意事项：
性能分析

aof运维：
append only

rdb运维：
压缩文件，只能全量，一次全量写入，不能增量

配置文件中的save是写rdb：
save <seconds> <changes>
多少秒写一次，多少改变写一次，这2个条件，谁先达到条件，就写一次，条件是或者的关系
save 900 1     -- 900s内1个改变，重新写入一次rdb
save 300 10    -- 300s内有10个改变，重新写一次rdb
save 60 10000  -- 60秒内有10000个改变，写一次rdb
每次都要重写一次rdb，会对系统资源开销过重，特别是内存，内存不够用，很多redis实例时，则发生oom
生产上建议将系统自动写rdb给关闭

如果解决写rdb问题：
自己写程序，如每隔1小时写一次rdb，先判断内存等资源使用情况，再做bgsave

如果同时存在rdb和aof，重启redis，redis会先加载谁：
aof是明文存放所有操作过程
如果没有rdb，那么会一条条重放aof中的日志，有点类似于binlog

for i in  range(1,100000):
    set a str(i)  -- aof会记录下整个循环过程，从1 set到 99999过程
get a -> 99999 -- 最终这个key的记录结果为a = 99999,其它key也是类似，这样就减少中间过程

这样下去aof文件会非常大，可能会一直追加到几百g，如何解决：
每天晚上重写生成aof，即aof重写，利用现在内存中的数据重写aof文件
那么上面循环在aof文件中只会记录1条set a 99999, 命令 bgrewriteaof进行aof重写
这样大小从原来几百g，变成几个g

如果同时存在rdb和aof，重启redis，redis会先加载谁，测试：

清空redis数据(内存)：
flushdb
select 0
flushdb
info

清空redis数据(磁盘)：
bgrewriteaof
6379.aof文件变为0

观察日志

关闭redis

启动redis

登陆redis：
redis>info
# keyspace
发现是没有数据的

redis>bgsave -- 因为内存没有数据，将其写入磁盘，则会清空磁盘上.rdb文件内容
日志中可以看到copy-on-write过程

set a1 '1'
bgsave  -- 此时.rdb文件中只有一条数据a1=1
可以通过rdb --command json 6379.rdb文件来查看

set a2 '2'

然后kill redis进程

然后启动redis：
日志中可以看到：db loaded from append only file -- 表示来自于aof

登陆redis：
info
#keyspace
db0:keys=2

keys * -- 发现2个可以都存在
如果aof和rdb都存在，则会从aof中加载

强制从rdb文件中加载数据：
如果把aof文件删掉，则默认不会从rdb文件中加载数据

rdb文件要不要做备份并备份到走：
rdb只在slave上做，放在本地也可以
只配置aof，在slave上手工做rdb，对redis性能比较好

6379。conf:
appendonly no

再次启动redis，就会从rdb中加载

4。0
总结：同时存在aof and rdb，则从aof存在，如果想从rdb加载，则需要禁用aof配置文件

主库：
aof
bgrewriteaof 要求每天做一次

从库：
rdb文件，建议在从库上备份，如果是做持久化，需要做历史备份


主从是通过rdb文件来实现的：
主从时，slave发出请求，master会自动生成一份rdb文件给slave，然后再做增量

怎么控制aof大小？
可以通过redis内存大小限制+每天重写一次aof

redis难在设计上：
怎么做一次快速排序？怎么快速映射用户信息到redis等

redis配置文件：

https://github.com/xueqiu/rdr
RDR(redis data reveal) is a tool to parse redis rdbfile. Comparing to redis-rdb-tools, RDR is implemented by golang, much faster (5GB rdbfile takes about 2mins on my PC).
A635-潘东林-北京 redis图形比较好

mysql slave 触发器默认是不工作的




