前提MGR正常:
$ cat /etc/redhat-release
CentOS Linux release 7.5.1804 (Core)

$ uname -rm
3.10.0-862.3.2.el7.x86_64 x86_64

$ ll /etc/localtime 
lrwxrwxrwx 1 root root 33 Jul 30 13:27 /etc/localtime -> /usr/share/zoneinfo/Asia/Shanghai

$ date
Sun Aug 18 17:28:11 CST 2019


MGR：mysql-8.0.17-linux-glibc2.12-x86_64

SQL> select version();
+-----------+
| version() |
+-----------+
| 8.0.17    |
+-----------+
1 row in set (0.00 sec)

 
SQL> select * from performance_schema.replication_group_members;
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST  | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| group_replication_applier | 3cfe5330-b2bb-11e9-9d5c-fa163e17c322 | 10.180.52.37 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 417ceb5a-b2b3-11e9-99ce-fa163e73cb8f | 10.180.52.35 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 9e3b5773-b2b8-11e9-be32-fa163e8abbc3 | 10.180.52.36 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
3 rows in set (0.00 sec)



MGR三个节点在不同服务器上，每个节点是单实例，配置差异部分通过斜杠代表/，表示或者意思:

## log time and level
log_timestamps=SYSTEM
log_error_verbosity=3

## binary log
log_bin=/xxx/binlog/mysql-bin
log_bin_index=/xxx/binlog/mysql-bin.index
log_bin_trust_function_creators=1
binlog_rows_query_log_events=1
#max_binlog_files=200
#binlog_space_limit=22300000000
max_binlog_size=200M
binlog_format=ROW
binlog_row_image=FULL
#expire_logs_days=5
binlog_expire_logs_seconds=604800
binlog_cache_size=4M
max_binlog_cache_size=2G

## relay log
relay_log=/xxx/relaylog/mysql-relay-bin
relay_log_index=/xxx/relaylog/mysql-relay-bin.index
relay_log_recovery=1
relay_log_purge=1

## parallel and order
slave_parallel_type=LOGICAL_CLOCK
slave_parallel_workers=4
slave_preserve_commit_order=ON

## mysqlx
mysqlx=ON
mysqlx_port=20000 / 20001 / 2002
mysqlx_socket=/xxx/mysqlx.sock

## mysql group replication
server_id=52353316 / 52363316 / 52373316
gtid_mode=ON
enforce_gtid_consistency=ON
master_info_repository=TABLE
relay_log_info_repository=TABLE

log_slave_updates=ON
binlog_format=ROW
binlog_checksum=NONE

report_host='10.180.52.35' / '10.180.52.36' / '10.180.52.37'
#disabled_storage_engines='MyISAM,MRG_MYISAM,BLACKHOLE,FEDERATED,ARCHIVE,MEMORY,CSV'

## mgr single master
transaction_write_set_extraction=XXHASH64
loose-group_replication_group_name="ca436595-a562-451a-954e-6e80b20d7ccd"
loose-group_replication_start_on_boot=OFF
loose-group_replication_local_address="10.180.52.35:33161" / "10.180.52.36:33161" / "10.180.52.37:33161"
loose-group_replication_group_seeds="10.180.52.35:33161,10.180.52.36:33161,10.180.52.37:33161"
loose-group_replication_bootstrap_group=OFF

## mgr ip whitelist
#loose-group_replication_ip_whitelist='10.39.3.76/24,10.39.3.70/24,10.39.3.69/24,10.39.3.71/24,127.0.0.1/8'

## mgr single master
#loose-group_replication_single_primary_mode=ON
#loose-group_replication_enforce_update_everywhere_checks=OFF

## mgr multi master
loose-group_replication_single_primary_mode=OFF
loose-group_replication_enforce_update_everywhere_checks=ON


模拟网络问题：
之前MGR每个节点没有开启iptables，现在在节点52.37上设置iptables INPUT chain = DROP并没有设置其它accept规则，使其与另2个节点互相不能通信

# cat /etc/sysconfig/iptables
# sample configuration for iptables service
# you can edit this manually or use system-config-firewall
# please do not ask us to add additional ports/services to this default configuration
*filter
#:INPUT ACCEPT [0:0]
:INPUT DROP [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -p icmp -j ACCEPT
-A INPUT -i lo -j ACCEPT
-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT
-A INPUT -j REJECT --reject-with icmp-host-prohibited
-A FORWARD -j REJECT --reject-with icmp-host-prohibited
COMMIT


# systemctl restart iptables

然后在每个节点检测MGR成员状态:
SQL> select * from performance_schema.replication_group_members;

大概10s之后，52.37日志如下，其它2个节点没有日志输出
2019-08-18T16:44:49.738797+08:00 0 [Warning] [MY-011493] [Repl] Plugin group_replication reported: 'Member with address 10.180.52.35:3316 has become unreachable.'
2019-08-18T16:44:49.738889+08:00 0 [Warning] [MY-011493] [Repl] Plugin group_replication reported: 'Member with address 10.180.52.36:3316 has become unreachable.'
2019-08-18T16:44:49.738907+08:00 0 [ERROR] [MY-011495] [Repl] Plugin group_replication reported: 'This server is not able to reach a majority of members in the group. This server will now block all updates. The server will remain blocked until contact with the majority is restored. It is possible to use group_replication_force_members to force a new group membership.'

SQL> select * from performance_schema.replication_group_members;
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST  | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| group_replication_applier | 3cfe5330-b2bb-11e9-9d5c-fa163e17c322 | 10.180.52.37 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 417ceb5a-b2b3-11e9-99ce-fa163e73cb8f | 10.180.52.35 |        3316 | UNREACHABLE  | PRIMARY     | 8.0.17         |
| group_replication_applier | 9e3b5773-b2b8-11e9-be32-fa163e8abbc3 | 10.180.52.36 |        3316 | UNREACHABLE  | PRIMARY     | 8.0.17         |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
3 rows in set (0.00 sec)


SQL> select * from performance_schema.replication_group_members;
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST  | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| group_replication_applier | 3cfe5330-b2bb-11e9-9d5c-fa163e17c322 | 10.180.52.37 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 417ceb5a-b2b3-11e9-99ce-fa163e73cb8f | 10.180.52.35 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 9e3b5773-b2b8-11e9-be32-fa163e8abbc3 | 10.180.52.36 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
3 rows in set (0.00 sec)


SQL> select * from performance_schema.replication_group_members;
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST  | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| group_replication_applier | 3cfe5330-b2bb-11e9-9d5c-fa163e17c322 | 10.180.52.37 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 417ceb5a-b2b3-11e9-99ce-fa163e73cb8f | 10.180.52.35 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 9e3b5773-b2b8-11e9-be32-fa163e8abbc3 | 10.180.52.36 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
3 rows in set (0.00 sec)


此时在52.35上写入数据，发现会很慢,说明还认为52.37是online:
SQL> insert into t1 set name='x';                              
Query OK, 1 row affected (0.26 sec)

SQL> insert into t1 set name='x';
Query OK, 1 row affected (0.22 sec)

SQL> insert into t1 set name='x';
Query OK, 1 row affected (0.18 sec)


此时在52.37上写入数据，发现会很快，猜测是因为检测到其它2个节点状态为UNREACHABLE，就不再冲突检测:
SQL> begin;
Query OK, 0 rows affected (0.00 sec)

SQL> insert into t1 set name='a';
Query OK, 1 row affected (0.00 sec)

SQL> rollback;
Query OK, 0 rows affected (0.01 sec)


当网络恢复后，节点52.37可以正常加入MGR集群工作，其它2个节点依旧没有日志：
2019-08-18T16:37:59.903816+08:00 0 [Warning] [MY-011494] [Repl] Plugin group_replication reported: 'Member with address 10.180.52.35:3316 is reachable again.'
2019-08-18T16:37:59.903955+08:00 0 [Warning] [MY-011494] [Repl] Plugin group_replication reported: 'Member with address 10.180.52.36:3316 is reachable again.'
2019-08-18T16:37:59.904014+08:00 0 [Warning] [MY-011498] [Repl] Plugin group_replication reported: 'The member has resumed contact with a majority of the members in the group. Regular operation is restored and transactions are unblocked.'
2019-08-18T16:38:02.748023+08:00 57430 [Warning] [MY-010957] [Server] The replication timestamps have returned to normal values.

[57479 51 sys@127.0.0.1 10.180.52.37:3316 2019-08-18_17:18:03_7_CST (db1)]
SQL> select * from performance_schema.replication_group_members;
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| CHANNEL_NAME              | MEMBER_ID                            | MEMBER_HOST  | MEMBER_PORT | MEMBER_STATE | MEMBER_ROLE | MEMBER_VERSION |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
| group_replication_applier | 3cfe5330-b2bb-11e9-9d5c-fa163e17c322 | 10.180.52.37 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 417ceb5a-b2b3-11e9-99ce-fa163e73cb8f | 10.180.52.35 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
| group_replication_applier | 9e3b5773-b2b8-11e9-be32-fa163e8abbc3 | 10.180.52.36 |        3316 | ONLINE       | PRIMARY     | 8.0.17         |
+---------------------------+--------------------------------------+--------------+-------------+--------------+-------------+----------------+
3 rows in set (0.00 sec)



还有一个问题，日志中会经常出现：
2019-08-18T17:00:25.611746+08:00 0 [Note] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Failure reading from fd=-1 n=18446744073709551615'

MGR关闭某节点后，其它节点error.log收到信息:
2019-07-17T10:52:59.786592+08:00 0 [Note] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Failure reading from fd=54 n=0'

$ vim plugin/group_replication/libmysqlgcs/src/bindings/xcom/xcom/xcom_transport.c +1304
1282 /* See also :/static .*read_bytes */
1283 int read_msg(connection_descriptor *rfd, pax_msg *p, server *s, int64_t *ret) {
1284  int deserialize_ok = 0;
1285
1286  DECL_ENV
1287  int64_t n;
1288  char *bytes;
1289  unsigned char header_buf[MSG_HDR_SIZE];
1290  xcom_proto x_version;
1291  uint32_t msgsize;
1292  x_msg_type x_type;
1293  unsigned int tag;
1294  END_ENV;
1295
1296  TASK_BEGIN
1297  do {
1298    ep->bytes = NULL;
1299    /* Read length field, protocol version, and checksum */
1300    ep->n = 0;
1301    TASK_CALL(read_bytes(rfd, (char *)ep->header_buf, MSG_HDR_SIZE, s, &ep->n));
1302
1303    if (ep->n != MSG_HDR_SIZE) {
1304      G_INFO("Failure reading from fd=%d n=%" PRIu64, rfd->fd, ep->n);
1305      DBGOUT(FN; NDBG64(ep->n));
1306      TASK_FAIL;
1307    }
