                                                  第8章  选择合适的数据类型

在使用 MySQL 创建数据表时都会遇到一个问题,如何为字段选择合适的数据类型?
    例如,创建一张员工表用来记录员工的信息,这时对员工的各种属性如何来进行定义?也许大家会想,这个问题很简单,每个字段可以使用很多种数据类型来定义,
         比如 int、float、double、 decimal 等。其实正因为可选择的数据类型太多,才需要依据一些原则来“挑选”最适合的 数据类型
         本章将详细介绍字符、数值、日期数据类型的一些选择原则


8.1 CHAR与VARCHAR

CHAR 和 VARCHAR 类型类似,都用来存储字符串,但它们保存和检索的方式不同:
     CHAR 属于固定长度的字符类型,而 VARCHAR 属于可变长度的字符类型

表 8-1 显示了将各种字符串值保存到 CHAR(4)和 VARCHAR(4)列后的结果,说明了 CHAR 和 VARCHAR 之间的差别。

表 8-1 CHAR 和 VARCHAR 的对比
值            CHAR(4)   存储需求   VARCHAR(4)    存储需求
''            '  '      4 个字节   ''            1 个字节
'ab'          'ab '     4 个字节   'ab '         3 个字节
'abcd'        'abcd'    4 个字节   'abcd'        5 个字节
'abcdefgh'    'abcd'    4 个字节   'abcd'        5 个字节

请注意表 8-1 中最后一行的值只适用非“严格模式”时,如果 MySQL 运行在严格模式, 超过列长度的值将不会保存,并且会出现错误提示,
关于“严格模式”将在第 16 章的 SQL MODE 及其相关问题的章节中详细介绍

从 CHAR(4)和 VARCHAR(4)列检索的值并不总是相同,因为检索时从 CHAR 列删除了尾部 的空格。
下面通过一个例子说明该差别:
mysql> create table vc (v varchar(4), c char(4));
Query OK, 0 rows affected (0.02 sec)

mysql> desc vc;
+-------+------------+------+-----+---------+-------+
| Field | Type       | Null | Key | Default | Extra |
+-------+------------+------+-----+---------+-------+
| v     | varchar(4) | YES  |     | NULL    |       |
| c     | char(4)    | YES  |     | NULL    |       |
+-------+------------+------+-----+---------+-------+
2 rows in set (0.00 sec)

mysql> insert into vc values ('ab  ','ab  ');
Query OK, 1 row affected (0.00 sec)

mysql> select * from vc;
+------+------+
| v    | c    |
+------+------+
| ab   | ab   |
+------+------+
1 row in set (0.00 sec)

mysql> select concat(v, '+'),concat(c, '+') from vc;
+----------------+----------------+
| concat(v, '+') | concat(c, '+') |
+----------------+----------------+
| ab  +          | ab+            |
+----------------+----------------+
1 row in set (0.00 sec)


1.由于 CHAR 是固定长度的,所以它的处理速度比 VARCHAR 快得多,
2.但是其缺点是浪费 存储空间,程序需要对行尾空格进行处理,
      所以对于那些长度变化不大并且对查询速度有较高要求的数据可以考虑使用 CHAR 类型来存储
3.随着 MySQL 版本的不断升级,VARCHAR 数据类型的性能也在不断改进并提高,所以在许多的应用中,VARCHAR类型被更多地使用


在 MySQL 中,不同的存储引擎对 CHAR 和 VARCHAR 的使用原则有所不同,这里简单概括如下:
1.MyISAM 存储引擎: 建议使用固定长度的数据列代替可变长度的数据列
2.MEMORY 存储引擎: 目前都使用固定长度的数据行存储,因此无论使用 CHAR 或 VARCHAR 列都没有关系
   两者都是作为 CHAR 类型处理
3.InnoDB 存储引擎: 建议使用 VARCHAR 类型
   对于 InnoDB 数据表,内部的行存储格式没有区分固定长度和可变长度列(所有数据行都使用指向数据列值的头指针),
   因此在本质上,使用固定长度的 CHAR 列不一定比使用可变长度 VARCHAR 列性能要好
   因而,主要的性能因素是数据行使用的存储总量
   由于CHAR平均占用的空间多于 VARCHAR,因此使用 VARCHAR 来最小化需要处理的数据行的存储总量和磁盘 I/O 是比较好的




8.2 TEXT与BLOB

1.一般在保存少量字符串的时候,我们会选择 CHAR 或者 VARCHAR;
2.而在保存较大文本时, 通常会选择使用 TEXT 或者 BLOB,
3.二者之间的主要差别是 BLOB 能用来保存二进制数据,比如 照片
4.而 TEXT 只能保存字符数据,比如一篇文章或者日记
5.TEXT 和 BLOB 中有分别包括 TEXT、MEDIUMTEXT、LONGTEXT 和 BLOB、MEDIUMBLOB、LONGBLOB3 种不同的类型,
  它们之间的主要区别是存储文本长度不同和存储字节不同,用户应该根据实际情况选择能够满足 需求的最小存储类型


本节主要对 BLOB 和 TEXT 存在的一些常见问题进行介绍。

1.BLOB和TEXT值会引起一些性能问题,特别是在执行了大量的删除操作时
2.删除操作会在数据表中留下很大的“空洞”,以后填入这些“空洞”的记录在插入的性能上会有影响
3.为了提高性能,建议定期使用OPTIMIZE TABLE功能对这类表进行碎片整理,避免因为“空洞”导致性能问题

下面的例子描述了 OPTIMIZE TABLE 的碎片整理功能
(1)创建测试表 t,字段 id 和 context 的类型分别为 varchar(100)和 text:

root@localhost[test] >use test
Database changed
root@localhost[test] >create table t (id varchar(100), context text);
Query OK, 0 rows affected (0.02 sec)

root@localhost[test] >desc t;
+---------+--------------+------+-----+---------+-------+
| Field   | Type         | Null | Key | Default | Extra |
+---------+--------------+------+-----+---------+-------+
| id      | varchar(100) | YES  |     | NULL    |       |
| context | text         | YES  |     | NULL    |       |
+---------+--------------+------+-----+---------+-------+
2 rows in set (0.02 sec)


(2)往 t 中插入大量记录,这里使用 repeat 函数插入大字符串:
root@localhost[test] >insert into t values(1,repeat('haha',100));
Query OK, 1 row affected (0.01 sec)

root@localhost[test] >insert into t values(2,repeat('haha',100));
Query OK, 1 row affected (0.01 sec)

root@localhost[test] >insert into t values(3,repeat('haha',100));
Query OK, 1 row affected (0.01 sec)

root@localhost[test] >insert into t select * from t;
Query OK, 3 rows affected (0.01 sec)
Records: 3  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 6 rows affected (0.01 sec)
Records: 6  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 12 rows affected (0.01 sec)
Records: 12  Duplicates: 0  Warnings: 0


root@localhost[test] >insert into t values(4,repeat('haha',10000));
Query OK, 1 row affected (0.02 sec)

root@localhost[test] >insert into t values(4,repeat('haha',30000));
ERROR 1406 (22001): Data too long for column 'context' at row 1
root@localhost[test] >insert into t values(5,repeat('haha',20000));
ERROR 1406 (22001): Data too long for column 'context' at row 1
root@localhost[test] >insert into t values(5,repeat('haha',10000));
Query OK, 1 row affected (0.01 sec)

root@localhost[test] >insert into t values(6,repeat('haha',10000)); 
Query OK, 1 row affected (0.01 sec)

root@localhost[test] >insert into t values(7,repeat('haha',10000));
Query OK, 1 row affected (0.03 sec)

root@localhost[test] >insert into t values(8,repeat('haha',10000));
Query OK, 1 row affected (0.02 sec)

root@localhost[test] >insert into t select * from t;
Query OK, 29 rows affected (0.04 sec)
Records: 29  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 58 rows affected (0.05 sec)
Records: 58  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 116 rows affected (0.02 sec)
Records: 116  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 232 rows affected (0.06 sec)
Records: 232  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 464 rows affected (0.23 sec)
Records: 464  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 928 rows affected (0.19 sec)
Records: 928  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 1856 rows affected (0.33 sec)
Records: 1856  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 3712 rows affected (0.75 sec)
Records: 3712  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 7424 rows affected (1.84 sec)
Records: 7424  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 14848 rows affected (6.45 sec)
Records: 14848  Duplicates: 0  Warnings: 0

root@localhost[test] >insert into t select * from t;
Query OK, 29696 rows affected (39.55 sec)
Records: 29696  Duplicates: 0  Warnings: 0


(3)退出到操作系统下,查看表 t 的物理文件大小:
->/mysqldata/inst1/mydata/test]$ ll -thr t.*
-rw-r----- 1 mysql mysql 8.4K Jan 18 22:13 t.frm
-rw-r----- 1 mysql mysql 592M Jan 18 22:48 t.ibd


(4)从表 t 中删除 id 为“1”的数据,这些数据占总数据量的?:
root@localhost[test] >delete from t where id=1;
Query OK, 16384 rows affected (7.61 sec)


(5)再次退出到操作系统下,查看表 t 的物理文件大小:
->/mysqldata/inst1/mydata/test]$ ll -thr t.*
-rw-r----- 1 mysql mysql 8.4K Jan 18 22:13 t.frm
-rw-r----- 1 mysql mysql 592M Jan 18 22:51 t.ibd
物理大小没有变化


(6)接下来对表进行 OPTIMIZE(优化)操作:
root@localhost[test] >optimize table t;
+--------+----------+----------+-------------------------------------------------------------------+
| Table  | Op       | Msg_type | Msg_text                                                          |
+--------+----------+----------+-------------------------------------------------------------------+
| test.t | optimize | note     | Table does not support optimize, doing recreate + analyze instead |
| test.t | optimize | status   | OK                                                                |
+--------+----------+----------+-------------------------------------------------------------------+
2 rows in set (30.97 sec)


(7)再次查看表 t 的物理文件大小:
->/mysqldata/inst1/mydata/test]$ ll -thr t.*
-rw-r----- 1 mysql mysql 8.4K Jan 18 22:52 t.frm
-rw-r----- 1 mysql mysql 580M Jan 18 22:52 t.ibd


root@localhost[test] >delete from t where id=2;
Query OK, 16384 rows affected (6.98 sec)

root@localhost[test] >commit;
Query OK, 0 rows affected (0.00 sec)

->/mysqldata/inst1/mydata/test]$ ll -thr t.*
-rw-r----- 1 mysql mysql 8.4K Jan 18 22:52 t.frm
-rw-r----- 1 mysql mysql 580M Jan 18 22:54 t.ibd



root@localhost[test] >optimize table t;        
+--------+----------+----------+-------------------------------------------------------------------+
| Table  | Op       | Msg_type | Msg_text                                                          |
+--------+----------+----------+-------------------------------------------------------------------+
| test.t | optimize | note     | Table does not support optimize, doing recreate + analyze instead |
| test.t | optimize | status   | OK                                                                |
+--------+----------+----------+-------------------------------------------------------------------+
2 rows in set (29.96 sec)


->/mysqldata/inst1/mydata/test]$ ll -thr t.*
-rw-r----- 1 mysql mysql 8.4K Jan 18 22:54 t.frm
-rw-r----- 1 mysql mysql 512M Jan 18 22:54 t.ibd

可以发现,表的数据文件大大缩小,“空洞”空间已经被回收




可以使用合成的(Synthetic)索引来 高大文本字段(BLOB 或 TEXT)的查询性能:

1.简单来说,合成索引就是根据大文本字段的内容建立一个散列值,并把这个值存储在单独的数据列中,
接下来就可以通过检索散列值找到数据行了
2.但是,要注意这种技术只能用于精确匹配的查询(散列值对于类似<或>=等范围搜索操作符是没有用处的)
3.可以使用 MD5() 函数生成散列值,也可以使用 SHA1()或 CRC32(),或者使用自己的应用程序逻辑来计算散列值
4.请记住数值型散列值可以很高效率地存储,同样,如果散列算法生成的字符串带有尾部空格,
  就不要把它们存储在 CHAR 或 VARCHAR 列中,它们会受到尾部空格去除的影响
5.合成的散列索引对于那些 BLOB 或 TEXT 数据列特别有用
  用散列标识符值查找的速度比搜索 BLOB 列本身的速度快很多
  

下面通过实例介绍一下合成索引的使用方法
(1)创建测试表 t,字段 id、context、hash_value 字段类型分别为 varchar(100)、blob、 varchar(40):
mysql> use test;
Database changed
mysql> drop table t;
Query OK, 0 rows affected (0.00 sec)

mysql> create table t (id varchar(100), context blob, hash_value varchar(40))
    -> ;
Query OK, 0 rows affected (0.01 sec)

mysql> desc t;
+------------+--------------+------+-----+---------+-------+
| Field      | Type         | Null | Key | Default | Extra |
+------------+--------------+------+-----+---------+-------+
| id         | varchar(100) | YES  |     | NULL    |       |
| context    | blob         | YES  |     | NULL    |       |
| hash_value | varchar(40)  | YES  |     | NULL    |       |
+------------+--------------+------+-----+---------+-------+
3 rows in set (0.00 sec)


(2)t 中插入测试数据,其中 hash_value 用来存放 context 列的 MD5 散列值:
mysql> insert into t values(1, repeat('beijing', 2), md5(context));
Query OK, 1 row affected (0.00 sec)

mysql> insert into t values(2, repeat('beijing 2008', 2), md5(context));
Query OK, 1 row affected (0.00 sec)

mysql> insert into t values(3, repeat('beijing 2008', 2), md5(context));
Query OK, 1 row affected (0.00 sec)

mysql> select * from t;
+------+--------------------------+----------------------------------+
| id   | context                  | hash_value                       |
+------+--------------------------+----------------------------------+
| 1    | beijingbeijing           | 09746eef633dbbccb7997dfd795cff17 |
| 2    | beijing 2008beijing 2008 | 1c0ddb82cca9ed63e1cacbddd3f74082 |
| 3    | beijing 2008beijing 2008 | 1c0ddb82cca9ed63e1cacbddd3f74082 |
+------+--------------------------+----------------------------------+
3 rows in set (0.00 sec)


(3)如果要查询 context 值为“beijing 2008beijing 2008”的记录,可以通过相应的散列值来 查询:
mysql> select * from t where hash_value=md5(repeat('beijing',2));
+------+----------------+----------------------------------+
| id   | context        | hash_value                       |
+------+----------------+----------------------------------+
| 1    | beijingbeijing | 09746eef633dbbccb7997dfd795cff17 |
+------+----------------+----------------------------------+
1 row in set (0.01 sec)

mysql> select * from t where hash_value=md5(repeat('beijing 2008',2));
+------+--------------------------+----------------------------------+
| id   | context                  | hash_value                       |
+------+--------------------------+----------------------------------+
| 2    | beijing 2008beijing 2008 | 1c0ddb82cca9ed63e1cacbddd3f74082 |
| 3    | beijing 2008beijing 2008 | 1c0ddb82cca9ed63e1cacbddd3f74082 |
+------+--------------------------+----------------------------------+
2 rows in set (0.00 sec)


上面的例子展示了合成索引的用法,由于这种技术只能用于精确匹配,在一定程度上减少 I/O,从而 高查询效率

如果需要对 BLOB 或者 CLOB 字段进行模糊查询,MySQL 提供了 前缀索引,也就是只为字段的前 n 列创建索引,举例如下:
mysql> create index idx_blob on t(context(100));
Query OK, 0 rows affected (0.02 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql> desc select * from t where context like 'beijing%'\G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: t
   partitions: NULL
         type: ALL
possible_keys: idx_blob
          key: NULL
      key_len: NULL
          ref: NULL
         rows: 3
     filtered: 100.00
        Extra: Using where
1 row in set, 1 warning (0.01 sec)


可以发现,对 context 前 100 个字符进行模糊查询,就可以用到前缀索引
请注意,这里的 查询条件中,“%”不能放在最前面,否则索引将不会被使用。


1.在不必要的时候避免检索大型的 BLOB 或 TEXT 值
  例如,SELECT * 查询就不是很好的想法,除非能够确定作为约束条件的 WHERE 子句只会找 到所需要的数据行
       否则,很可能毫无目的地在网络上传输大量的值。这也是 BLOB 或 TEXT 标识符信息存储在合成的索引列中
       对用户有所帮助的例子。用户可以搜索索引列,决定需要的哪些数据行,然后从符合条件的数据行中检索BLOB 或 TEXT值


2.把 BLOB 或 TEXT 列分离到单独的表中
  在某些环境中,如果把这些数据列移动到第二张数据表中,可以把原数据表中的数据列转换为固定长度的数据行格式,
  那么它就是有意义的。这会减少主表中的碎片,可以得到固定长度数据行的性能优势
  它还可以使主数据表在运行 SELECT * 查询的时候不会通过网络传输大量的 BLOB 或 TEXT 值



